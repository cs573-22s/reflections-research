This week's reflection is coming from https://link.springer.com/content/pdf/10.1007/978-3-540-76856-2_64.pdf. This paper examines two questions about measuring effective data visualization: how effective the visualization is and how to measure its effectiveness. This is an interesting topic for me, because I think visualizations that are very well-designed can seem very effective because they are pleasing for the eye to look at, but could have completely indigestible information. I find this mistake often in UX designs - there are many beautiful ones, but that are useless or difficult to use for simple tasks. 

This paper goes into examining how to make that distinction of effectiveness about a visualization. It was found that there are no specific guidelines about what deems a visualization “effective,” and there are many different views on it. This paper studied the different existing measures of effectiveness and any limitations they may have. The researchers focused on the interactions between visualization, data, task, and user. The two methods for evaluating the effectiveness are heuristic evaluation and user studies. The former is when a visualization is evaluated based on set rules and principles and generates qualitative measures of effectiveness. A limitation of this method is that these rules are not empirically validated, can be abstract, and are presented without much context. The user study, which is the most common type, looks at task completion time, error rate and user satisfaction. Their limitations include not having a specific cause of performance problem, a lack of standard benchmark databases, tasks, and measures. 

In conclusion, the study states that a visualization should be studied based on accuracy, utility, and efficiency. All of these can be studied in quantitative and qualitative ways. 
